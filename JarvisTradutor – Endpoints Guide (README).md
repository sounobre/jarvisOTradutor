# üìö JarvisTradutor ‚Äì Documenta√ß√£o T√©cnica Completa

## 1. Introdu√ß√£o

O **JarvisTradutor** √© uma plataforma para tradu√ß√£o assistida de textos e livros, com foco em literatura fant√°stica (romances, s√©ries longas, gloss√°rios espec√≠ficos por obra).
Seu objetivo √© **criar, alinhar e armazenar mem√≥rias de tradu√ß√£o (TM)** e **vetores sem√¢nticos (embeddings)** para:

* Auxiliar tradu√ß√µes autom√°ticas de alta qualidade.
* Manter consist√™ncia em gloss√°rios espec√≠ficos de cada s√©rie/livro.
* Permitir an√°lise futura de qualidade comparando tradu√ß√µes autom√°ticas com vers√µes oficiais.
* Servir de base para **fine-tuning** de modelos de tradu√ß√£o.

---

## 2. Arquitetura T√©cnica

O sistema √© dividido em **3 camadas principais**:

### üü¶ Backend Java (Spring Boot)

* Orquestra√ß√£o, regras de neg√≥cio e banco de dados.
* Servi√ßos:

  * Importa√ß√£o de corpus paralelo (TSV, CSV, EPUBs).
  * Deduplica√ß√£o, filtragem por qualidade.
  * Consolida√ß√£o staging ‚Üí TM principal.
  * Gest√£o de gloss√°rio, s√©ries e livros.

### üü© Embeddings API (FastAPI, Python)

* Gera√ß√£o de embeddings (vetores sem√¢nticos) usando **SentenceTransformers**.
* Comunica√ß√£o via HTTP (`/embed`).
* Permite alinhamento sem√¢ntico de frases.

### üêç Worker Python (opcional)

* Focado na tradu√ß√£o direta de EPUBs.
* Integra com o backend Java para aplicar TM e gloss√°rios.
* Pode aplicar t√©cnicas como retradu√ß√£o seletiva e p√≥s-edi√ß√£o.

### üîó Banco de Dados (PostgreSQL + pgvector)

Tabelas principais:

* `tm` ‚Üí mem√≥ria de tradu√ß√£o consolidada.
* `tm_embeddings` ‚Üí embeddings associados a pares da TM.
* `tm_staging` / `tm_emb_staging` ‚Üí tabelas tempor√°rias para importa√ß√£o.
* `tm_occurrence` ‚Üí ocorr√™ncia dos pares, associando s√©rie, livro, cap√≠tulo e posi√ß√£o.
* `series` e `books` ‚Üí cat√°logo de s√©ries e livros, para manter gloss√°rios espec√≠ficos.

---

## 3. Fluxo de Importa√ß√£o

1. **Recebe arquivos paralelos (TSV/CSV/EPUBs).**
2. **Normaliza textos:** remove ru√≠dos, aplica regras de placeholders.
3. **Filtra por qualidade:** raz√£o de comprimento, placeholders preservados, score final.
4. **Escreve em staging:**

   * `tm_staging` (pares texto).
   * `tm_emb_staging` (se embeddings forem gerados).
   * `tm_occurrence_staging` (associa√ß√£o s√©rie/livro).
5. **Consolida:**

   * `tm` recebe os pares √∫nicos.
   * `tm_embeddings` recebe os vetores.
   * `tm_occurrence` recebe as liga√ß√µes contextuais.

---

## 4. Classes Principais

### üìå `TMImportServiceImpl`

Respons√°vel pela importa√ß√£o de **corpora paralelos (TSV/CSV)**.
Fun√ß√µes principais:

* `importTsvOrCsvStreaming` ‚Üí streaming via COPY.
* `importTxtResume` ‚Üí importa√ß√£o resum√≠vel (checkpoint).
* Deduplica√ß√£o por lote.
* Score de qualidade (`ratio + placeholders`).
* Envio de embeddings para API.

Trecho chave (flush embeddings):

```java
private void flushEmbeddingsBuffer(Writer outEmb,
                                   List<String> bufSrc,
                                   List<String> bufTgt,
                                   List<String> bufLangSrc,
                                   List<String> bufLangTgt,
                                   List<Double> bufQ,
                                   String embedMode) throws IOException {
    List<double[]> vecSrc = embedTexts(bufSrc, true);
    List<double[]> vecTgt = "both".equals(embedMode) ? embedTexts(bufTgt, true) : List.of();

    for (int i = 0; i < bufSrc.size(); i++) {
        String src = bufSrc.get(i);
        String tgt = bufTgt.get(i);
        String ls = bufLangSrc.get(i);
        String lt = bufLangTgt.get(i);
        Double q  = bufQ.get(i);

        String embSrc = vecSrc.isEmpty() ? "" : toVectorLiteral(vecSrc.get(i));
        String embTgt = (!vecTgt.isEmpty()) ? toVectorLiteral(vecTgt.get(i)) : "";

        outEmb.write(String.format("\"%s\",\"%s\",\"%s\",\"%s\",\"%s\",\"%s\",%f\n",
                esc(src), esc(tgt), esc(ls), esc(lt), embSrc, embTgt, q));
    }
    bufSrc.clear(); bufTgt.clear(); bufLangSrc.clear(); bufLangTgt.clear(); bufQ.clear();
}
```

---

### üìå `EPUBPairImportServiceImpl`

Importa e alinha **EPUBs paralelos (EN/PT)**.
Destaques:

* Extra√ß√£o de blocos com **epublib** + **Jsoup**.
* Alinhamento por **comprimento** ou **similaridade sem√¢ntica (embeddings)**.
* Uso de **arquivos tempor√°rios** para staging de embeddings (evita backpressure).
* Integra√ß√£o com `tm_occurrence` (salva s√©rie/livro/cap√≠tulo).



Quer que eu continue agora at√© fechar **Controllers + Endpoints (com todos os exemplos curl)** ou prefere que eu j√° finalize este bloco e gere o **PDF parcial** para voc√™ dar uma olhada?


Show, meu amigo üöÄ
Vou ent√£o complementar a documenta√ß√£o com os **Controllers + Endpoints (cURLs)** e fechar o documento completo em **Markdown**. Depois gero o **PDF final**.


---

## 5. Controllers e Endpoints

### üîπ `GlossaryController`

#### `POST /glossary/bulk`

* Upsert em lote de termos do gloss√°rio.
* Resolve conflitos por prioridade (`priority` mais alto vence).

**Exemplo cURL:**

```bash
curl -X POST http://localhost:8080/glossary/bulk \
  -H "Content-Type: application/json" \
  -d '[
    { "src": "dragon rider", "tgt": "cavaleiro de drag√£o", "priority": 10 },
    { "src": "outpost", "tgt": "guarni√ß√£o" }
  ]'
```

---

### üîπ `TMImportController`

#### `POST /tm/import`

* Importa corpus paralelo via **arquivo TSV/CSV**.
* Aplica dedupe, score e staging ‚Üí TM.

**Exemplo cURL:**

```bash
curl -X POST "http://localhost:8080/tm/import?delimiter=%09" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@/caminho/corpus.tsv"
```

---

#### `GET /tm/lookup`

* Consulta tradu√ß√£o existente.

**Exemplo cURL:**

```bash
curl -G "http://localhost:8080/tm/lookup" \
  --data-urlencode "src=The dragon flies at dawn."
```

---

#### `POST /tm/learn`

* Aprendizado online ‚Äì insere par src/tgt com embedding.

**Exemplo cURL:**

```bash
curl -X POST "http://localhost:8080/tm/learn" \
  --data-urlencode "src=Thank you" \
  --data-urlencode "tgt=Obrigado" \
  --data-urlencode "quality=0.95"
```

---

### üîπ `EPUBPairImportController`

#### `POST /import/epub-pair`

* Importa dois EPUBs paralelos (ex: ingl√™s/portugu√™s).
* Gera staging em:

  * `tm_staging`
  * `tm_emb_staging` (opcional, se `mode=embedding`)
  * `tm_occurrence_staging` (contexto: s√©rie/livro/cap√≠tulo)

**Par√¢metros:**

* `level` ‚Üí `paragraph` ou `sentence`.
* `mode` ‚Üí `length` ou `embedding`.
* `srcLang`, `tgtLang` ‚Üí l√≠nguas (default: en/pt).
* `minQuality` ‚Üí score m√≠nimo.
* `seriesId`, `bookId`, `sourceTag` ‚Üí metadados de ocorr√™ncia.

**Exemplo cURL:**

```bash
curl -X POST "http://localhost:8080/import/epub-pair?level=sentence&mode=embedding&srcLang=en&tgtLang=pt&minQuality=0.7&seriesId=1&bookId=3&sourceTag=fantasy_test" \
  -H "Content-Type: multipart/form-data" \
  -F "fileEn=@/livros/original.epub" \
  -F "filePt=@/livros/traducao.epub"
```

---

### üîπ `SeriesController`

#### `POST /series`

* Cria uma nova s√©rie (ex: *Stormlight Archive*).

**cURL:**

```bash
curl -X POST http://localhost:8080/series \
  -H "Content-Type: application/json" \
  -d '{"name": "Stormlight Archive", "description": "Saga de alta fantasia de Brandon Sanderson"}'
```

---

#### `GET /series`

* Lista todas as s√©ries.

```bash
curl http://localhost:8080/series
```

---

### üîπ `BookController`

#### `POST /books`

* Cadastra um livro vinculado a uma s√©rie.

```bash
curl -X POST http://localhost:8080/books \
  -H "Content-Type: application/json" \
  -d '{"title": "The Way of Kings", "seriesId": 1, "orderIndex": 1, "year": 2010}'
```

---

#### `GET /books/by-series/{seriesId}`

* Lista livros de uma s√©rie.

```bash
curl http://localhost:8080/books/by-series/1
```

---

## 6. Banco de Dados (Schemas Simplificados)

```sql
CREATE TABLE series (
  id BIGSERIAL PRIMARY KEY,
  name TEXT NOT NULL,
  description TEXT,
  created_at TIMESTAMP DEFAULT now()
);

CREATE TABLE books (
  id BIGSERIAL PRIMARY KEY,
  series_id BIGINT REFERENCES series(id),
  title TEXT NOT NULL,
  order_index INT,
  year INT,
  created_at TIMESTAMP DEFAULT now()
);

CREATE TABLE tm (
  id BIGSERIAL PRIMARY KEY,
  src TEXT NOT NULL,
  tgt TEXT NOT NULL,
  lang_src TEXT NOT NULL,
  lang_tgt TEXT NOT NULL,
  quality DOUBLE PRECISION,
  created_at TIMESTAMP DEFAULT now(),
  UNIQUE(src,tgt,lang_src,lang_tgt)
);

CREATE TABLE tm_embeddings (
  tm_id BIGINT PRIMARY KEY REFERENCES tm(id),
  emb_src VECTOR,
  emb_tgt VECTOR
);

CREATE TABLE tm_occurrence (
  id BIGSERIAL PRIMARY KEY,
  tm_id BIGINT REFERENCES tm(id),
  series_id BIGINT REFERENCES series(id),
  book_id BIGINT REFERENCES books(id),
  chapter TEXT,
  location TEXT,
  quality_at_import DOUBLE PRECISION,
  source_tag TEXT,
  created_at TIMESTAMP DEFAULT now()
);
```

---


# 7. Setup & Deploy

### üîß Requisitos

* **Java 21** + **Spring Boot 3.x**
* **PostgreSQL ‚â• 15** com extens√£o `pgvector`
* **Python 3.10+**
* **Docker** (opcional, mas recomendado para subir os servi√ßos juntos)

### üì¶ Instala√ß√£o Backend Java

```bash
cd jarvistradutor-backend
./mvnw clean package
java -jar target/jarvistradutor-backend.jar
```

Configura√ß√£o em `application.yml`:

```yaml
spring:
  datasource:
    url: jdbc:postgresql://localhost:5432/jarvis
    username: jarvis
    password: jarvis
  jpa:
    hibernate.ddl-auto: update
```

---

### üì¶ Instala√ß√£o Embeddings API

```bash
cd embeddings-api
pip install -r requirements.txt
uvicorn src.embeddings_api.main:app --host 0.0.0.0 --port 8001 --reload
```

---

### üì¶ Instala√ß√£o Worker Python (opcional)

```bash
cd worker
pip install -r requirements.txt
uvicorn app.main:app --host 0.0.0.0 --port 8002 --reload
```

---

### üöÄ Docker Compose - n√£o est√° sendo utilizado no momento estou levantando tudo na m√£o (Exemplo)

```yaml
version: "3.8"
services:
  db:
    image: postgres:15
    environment:
      POSTGRES_DB: jarvis
      POSTGRES_USER: jarvis
      POSTGRES_PASSWORD: jarvis
    ports:
      - "5432:5432"
  backend:
    build: ./jarvistradutor-backend
    ports:
      - "8080:8080"
    depends_on:
      - db
  embeddings:
    build: ./embeddings-api
    ports:
      - "8001:8001"
  worker:
    build: ./worker
    ports:
      - "8002:8002"
```

---

# 8. T√©cnicas Avan√ßadas

### ‚ö° Batching

* Processamos embeddings em **lotes** (`EMB_BATCH=128` ou `512`).
* Reduz chamadas HTTP ‚Üí maior throughput.
* Evita **OOM (out-of-memory)** no Python.

### üíæ Flush

* `flush()` √© usado para aliviar o buffer e liberar dados pro **pipe** ou pro **arquivo tempor√°rio**.
* No staging de embeddings, s√≥ flush por lote.
* Fechamento (`close()`) √© o sinal de EOF pro PostgreSQL `COPY`.

### üîÑ Backpressure

* Conceito: se o **consumidor** (PostgreSQL COPY) n√£o consegue ler na mesma velocidade que o **produtor** (Java escrevendo CSV), o buffer enche e trava.
* Resolvemos isso:

  * com `flush()` peri√≥dico (a cada 8‚Äì16 linhas).
  * com **arquivo tempor√°rio** em disco (em vez de pipe).

---

# 9. Roadmap Futuro üöÄ

1. **Fine-tuning** com corpus espec√≠fico (ex: fantasia √©pica).

   * Usar LoRA em GPUs alugadas (Colab, Paperspace).
   * Treinar embeddings adaptados ao g√™nero.

2. **Avalia√ß√£o de Qualidade**

   * Comparar nossas tradu√ß√µes com vers√µes oficiais.
   * Armazenar m√©tricas BLEU, TER e BERTScore na tabela `tm_occurrence`.

3. **UI Admin (React + Tailwind + Shadcn)**

   * CRUD de s√©ries/livros.
   * Dashboard de importa√ß√µes.
   * Relat√≥rios de qualidade.

4. **Integra√ß√£o com LLM p√≥s-edi√ß√£o**

   * Retradu√ß√£o autom√°tica dos 10% piores pares.
   * Aplica√ß√£o de gloss√°rio **constrained decoding**.

---

üëâ Agora sim, meu amigo, temos uma **documenta√ß√£o complet√≠ssima**:

* Arquitetura
* APIs com cURLs
* Banco de dados
* Controllers
* Setup & Deploy
* T√©cnicas avan√ßadas
* Roadmap

